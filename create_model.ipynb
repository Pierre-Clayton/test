{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.metrics import mean_squared_error, classification_report, confusion_matrix \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input \n",
    "from tensorflow.keras.regularizers import l1_12\n",
    "\n",
    "import random\n",
    "import os\n",
    "\n",
    "import nbimporter \n",
    "import useful \n",
    "\n",
    "def all_models(df_brut, k_iqr, column_name, column, train_coeff, val_coeff, test_coeff, lookback, units, l1, l2, learning_rate, epochs, batch_size, n_estimators, random_state) :\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    df _brut (pd.DataFrame): le dataset initial \n",
    "    k (int): le coeff dans IQR\n",
    "    column name (str): le nom de la colonne qui nous interesse pour la time series (ex: bid ou ask) \n",
    "    column (str): ask or bid\n",
    "    \"\"\"\n",
    "\n",
    "    ####################### manage data\n",
    "    data_brut = df_brut[column_name]\n",
    "    # créer une nouvelle colonne qui aura les indices du dataframe original (le df_brut), pour pouvoir les garder\n",
    "    df_brut['index_column'] = df_brut.index\n",
    "\n",
    "    ####################### IQR\n",
    "    # détecter les outliers avec IQR\n",
    "    detected_outlier_indices = useful.detect_IQR(df_brut, k_iqr, column_name)\n",
    "\n",
    "    # créer des labels et ecrire la liste des true outliers\n",
    "    labels_first = df_brut['true_outliers']\n",
    "    true_outlier_indices = df_brut[labels_first == 1].index.tolist()\n",
    "\n",
    "    # la liste commune entre les outliers detectes avec IQR et les vrais outliers\n",
    "    comm = [i for i in detected_outlier_indices.tolist() if i in true_outlier_indices]\n",
    "\n",
    "    # affichage et visualisation\n",
    "    print(\"Metriques IQR\")\n",
    "    useful.afficher_metriques(comm, true_outlier_indices, detected_outlier_indices.tolist(), column)\n",
    "\n",
    "    ####################### update data after finding first big outliers with IQR\n",
    "    # enlever les outliers deja detectés par le IQR et crer un nouveau dataframe df sans ces outliers aberrants\n",
    "    df = df_brut.drop(detected_outlier_indices)\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # créer les nouveaux labels et les nouveaux indices des vrais outliers\n",
    "    labels = df['true_outliers']\n",
    "    outlier_indices = df[labels == 1].index.tolist()\n",
    "    data = df[column_name]\n",
    "\n",
    "    ####################### LSTM + RF\n",
    "    # créer les séquences pour le LSTM\n",
    "    X,y,y_labels = useful.create_sequences(data, labels, lookback)\n",
    "\n",
    "    # découper les données en train (60%), validation (20%) et test (20%)\n",
    "    # la taille du debut à la fin de train (donc le nombre de données de train)\n",
    "    train_size = int(len(X) * train_coeff)\n",
    "    # la taille des données de validation\n",
    "    val_size = int(len(X) * val_coeff)\n",
    "\n",
    "    X_train, y_train, y_train_labels = X[:train_size], y[:train_size], y_labels[:train_size]\n",
    "    X_val, y_val, y_val_labels = X[train_size:train_size+val_size], y[train_size:train_size+val_size], y_labels[train_size:train_size+val_size]\n",
    "    X_test, y_test, y_test_labels = X[train_size+val_size:], y[train_size+val_size:], y_labels[train_size+val_size:]\n",
    "\n",
    "    # reshape pour LSTM\n",
    "    X_train_lstm = X_train.reshape(len(X_train), lookback, 1)\n",
    "    X_val_lstm = X_val.reshape(len(X_val), lookback, 1)\n",
    "    X_test_lstm = X_test.reshape(len(X_test), lookback, 1)\n",
    "\n",
    "    # construire et entrainer le modèle LSTM\n",
    "    model = useful.build_model(lookback, units, learning_rate, l1, l2)\n",
    "    history = model.fit(X_train_lstm, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val_lstm, y_val), verbose=0)\n",
    "\n",
    "    # affichage de la loss en fonction des epochs\n",
    "    useful.plot_loss_epochs(history)\n",
    "\n",
    "    # predire sur train, val et test\n",
    "    y_train_pred = model.predict(X_train_lstm)\n",
    "    y_val_pred = model.predict(X_val_lstm)\n",
    "    y_test_pred = model.predict(X_test_lstm)\n",
    "\n",
    "    # calculer les résidus\n",
    "    train_residuals = y_train - y_train_pred.flatten()\n",
    "    val_residuals = y_val - y_val_pred.flatten()\n",
    "    test_residuals = y_test - y_test_pred.flatten()\n",
    "\n",
    "    # préparer les données pour le classifier\n",
    "    X_train_rf, y_train_rf = useful.prepade_classifier_data(X_train, train_residuals, y_train_pred, y_train, y_train_labels)\n",
    "    X_val_rf, y_val_rf = useful.prepade_classifier_data(X_val, val_residuals, y_val_pred, y_val, y_val_labels)\n",
    "    X_test_rf, y_test_rf = useful.prepade_classifier_data(X_test, test_residuals, y_test_pred, y_test, y_test_labels)\n",
    "\n",
    "    # concatener les données de train et val pour le classifier\n",
    "    X_rf_train = np.vstack((X_train_rf, X_val_rf))\n",
    "    y_rf_train = np.hstack((y_train_rf, y_val_rf))\n",
    "\n",
    "    # entrainer le classifier\n",
    "    rf_classifier = RandomForestClassifier(n_estimators=n_estimators, random_state=random_state)\n",
    "    rf_classifier.fit(X_rf_train, y_rf_train)\n",
    "\n",
    "    # predire sur test\n",
    "    y_rf_pred = rf_classifier.predict(X_test_rf)\n",
    "\n",
    "    # les indices des outliers detectes par le Random Forest\n",
    "    outlier_indices_rf = np.where(y_rf_pred == 1)[0]\n",
    "\n",
    "    ####################### sauvegarde des modeles\n",
    "    # sauvegarder le modèle LSTM et le classifier\n",
    "    model.save('model_lstm.h5')\n",
    "    dump(rf_classifier, 'rf_classifier.joblib')\n",
    "\n",
    "    # affichage et visualisation\n",
    "    print(\"Metriques LSTM + RF\")\n",
    "    # evaluation du classifier\n",
    "    print(\"Classification report:\")\n",
    "    print(classification_report(y_test_rf, y_rf_pred))\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(confusion_matrix(y_test_rf, y_rf_pred))\n",
    "\n",
    "    ####################### acces aux outliers detectes\n",
    "    # calcul de l'indice de départ dans les données df\n",
    "    test_start_index = train_size + val_size + lookback\n",
    "\n",
    "    # indices des données du jeu de test dans les données df\n",
    "    data_indices_in_test_set = np.arange(len(y_test)) + test_start_index\n",
    "\n",
    "    # indices des outliers detectes dans les donnees df\n",
    "    outlier_data_indices = data_indices_in_test_set[outlier_indices_rf]\n",
    "\n",
    "    ####################### métriques totales avec indices originaux\n",
    "    outliers_data_indices_df_brut_rf = df['index_column'][outlier_data_indices].tolist()\n",
    "    outliers_data_indices_df_brut_rf.sort()\n",
    "\n",
    "    # couper les listes au niveau de la partie \"test\" pour pouvoir faire les comparaisons sur cette partie\n",
    "    nb_couper_test = int(len(df_brut) * (train_coeff + val_coeff))\n",
    "\n",
    "    detected_outlier_indices_iqr_test = useful.couper_liste(detected_outlier_indices.tolist(), nb_couper_test)\n",
    "    true_outlier_indices_test = useful.couper_liste(true_outlier_indices, nb_couper_test)\n",
    "\n",
    "    detected_outliers_total = detected_outlier_indices_iqr_test + outliers_data_indices_df_brut_rf\n",
    "    detected_outliers_total.sort()\n",
    "\n",
    "    comm_test_total = [i for i in detected_outliers_total if i in true_outlier_indices_test]\n",
    "\n",
    "    # affichage et visualisation\n",
    "    print(\"Metriques totales\")\n",
    "    useful.afficher_metriques(comm_test_total, true_outlier_indices_test, detected_outliers_total, column)\n",
    "\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
