{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Input\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import random\n",
    "import os\n",
    "from joblib import dump\n",
    "\n",
    "# FONCTIONS\n",
    "\"\"\"\n",
    "detect_IQR(df, k_iqr, column_name)\n",
    "afficher_listes_et_leurs_tailles(liste, nom_liste)\n",
    "calcul_metriques(comm, true, detected) \n",
    "afficher_metriques(comm, true, detected, column) \n",
    "create_sequences(data, labels, lookback=1)\n",
    "build_model(lookback, units, learning_rate, 11, 12)\n",
    "prepare_classifier_data(X sequences, residuals, y_pred, y_actual, labels) \n",
    "couper_liste(liste, x)\n",
    "plot_donnees_true_outliers_et_detect_with_iqr(data_brut)\n",
    "plot_loss_epochs(history)\n",
    "\"\"\"\n",
    "\n",
    "def detect_IQR(df, k_iqr, column_name):\n",
    "    d = df\n",
    "    Q1 = d.quantile(0.25)\n",
    "    Q3 = d.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    lower_bound = Q1 - k_iqr * IQR\n",
    "    upper_bound = Q3 + k_iqr * IQR\n",
    "\n",
    "    outlier_indices = df[(d<lower_bound) | (d>upper_bound)].index\n",
    "    return outlier_indices\n",
    "\n",
    "def afficher_listes_et_leurs_tailles(liste, nom_liste):\n",
    "    print(\"Taille de \", nom_liste, \" : \", len(liste))\n",
    "    print(f'Liste {nom_liste} : ', liste)\n",
    "\n",
    "def calcul_metriques(comm, true, detected):\n",
    "    tp = len(comm)\n",
    "    fp = len(detected) - len(comm)\n",
    "    fn = len(true) - len(comm)\n",
    "\n",
    "    if tp == 0:\n",
    "        precision = 0\n",
    "        recall = 0\n",
    "        f1 = 0\n",
    "    else:\n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    return precision, recall, f1\n",
    "\n",
    "def afficher_metriques(comm, true, detected, column):\n",
    "    # column: bid ou ask par exemple\n",
    "    res = calcul_metriques(comm, true, detected)\n",
    "    print(\"RESULTATS (metriques):\")\n",
    "    print('*'*22)\n",
    "    print(f'Column: {column}')\n",
    "    print('-'* 4)\n",
    "    print(f'Precision: {res[0]:.4f}')\n",
    "    print(f'Recall: {res[1]:.4f}')\n",
    "    print(f'F1: {res[2]:.4f}')\n",
    "    print('*'*22)\n",
    "\n",
    "def create_sequences(data, labels, lookback=1):\n",
    "    X, y, y_labels = [], [], []\n",
    "    for i in range(len(data) - lookback):\n",
    "        X.append(data[i:i+lookback])\n",
    "        y.append(data[i+lookback])\n",
    "        y_labels.append(labels[i+lookback])\n",
    "    return np.array(X), np.array(y), np.array(y_labels)\n",
    "\n",
    "def build_model(lookback, units, learning_rate, l1, l2):\n",
    "    model = Sequential([\n",
    "        Input(shape=(lookback, 1)),\n",
    "        LSTM(units, activation='relu', kernel_regularizer=l1_l2(l1, l2)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss='MeanSquaredError')\n",
    "    return model\n",
    "\n",
    "def prepare_classifier_data(X_sequences, residuals, y_pred, y_actual, labels):\n",
    "    # calculer la moyenne et l'écart-type de chaque séquence\n",
    "    seq_means = np.mean(X_sequences, axis=1)\n",
    "    seq_stds = np.std(X_sequences, axis=1)\n",
    "\n",
    "    # construire le dataframe des features\n",
    "    features = pd.DataFrame({\n",
    "        'residual': residuals,\n",
    "        'y_pred': y_pred.flatten(),\n",
    "        'seq_mean': seq_means,\n",
    "        'seq_std': seq_stds\n",
    "    })\n",
    "\n",
    "    # normalisation des features\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "    return features_scaled, labels\n",
    "\n",
    "def couper_liste(liste, x):\n",
    "    index = next((i for i, val in enumerate(liste) if val >= x), len(liste))\n",
    "    return liste[index:]\n",
    "\n",
    "def plot_donnees_true_outliers_et_detect_with_iqr(data_brut):\n",
    "    # le y\n",
    "    t = np.arange(0, len(data_brut))\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(t, data_brut, label='Donnes avec outliers')\n",
    "    plt.scatter(t[true_outlier_indices], data_brut[true_outlier_indices], color='red', label='Outliers')\n",
    "    plt.scatter(t[detected_outlier_indices], data_brut[detected_outlier_indices], color='black', label='Detectes')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_loss_epochs(history):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history.history['loss'], label='loss-training')\n",
    "    plt.plot(history.history['val_loss'], label='loss-validation')\n",
    "    plt.title('Loss en fonction des epochs')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
